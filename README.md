# ğŸ§  MCP Memory Server

**Give your AI a brain that never forgets.**

A persistent, cloud-synced memory server for AI assistants using the **Model Context Protocol (MCP)**. Works across Claude, Cursor, Windsurf, VS Code, Gemini CLI â€” all sharing the same memory in real-time.

> **Use case:** You're building a project in Cursor. You switch to Claude Code. It already knows what Cursor did â€” your architecture decisions, file changes, preferences â€” everything. Zero context repetition.

---

## ğŸš€ One-Command Setup

```bash
git clone https://github.com/prust/mcp-memory-server.git
cd mcp-memory-server
npm install && npm run build
node setup.mjs --user-id=YOUR_NAME
```

The setup script will:
- âœ… Verify your `serviceAccountKey.json`
- âœ… Build the project if needed
- âœ… Print **ready-to-paste configs** for every client

---

## ğŸ”Œ Connect Your Client (Pick One)

> Replace `YOUR_PATH` with the absolute path to this folder, and `YOUR_NAME` with your username.

### Claude Code
```bash
claude mcp add memory -- node YOUR_PATH/dist/index.js --user-id=YOUR_NAME
```
That's it. Done. âœ…

---

### Claude Desktop
File: `%APPDATA%\Claude\claude_desktop_config.json` (Win) Â· `~/Library/Application Support/Claude/claude_desktop_config.json` (Mac)

```json
{
  "mcpServers": {
    "memory": {
      "command": "node",
      "args": ["YOUR_PATH/dist/index.js", "--user-id=YOUR_NAME"]
    }
  }
}
```

---

### Cursor IDE
**Settings â†’ Features â†’ MCP â†’ + Add new MCP server**

| Field | Value |
|---|---|
| Type | `command` |
| Name | `memory` |
| Command | `node YOUR_PATH/dist/index.js --user-id=YOUR_NAME` |

---

### Windsurf / Codeium
File: `~/.codeium/windsurf/mcp_config.json`

```json
{
  "mcpServers": {
    "memory": {
      "command": "node",
      "args": ["YOUR_PATH/dist/index.js", "--user-id=YOUR_NAME"]
    }
  }
}
```

---

### VS Code (GitHub Copilot)
File: `.vscode/mcp.json` in your project

```json
{
  "mcp": {
    "servers": {
      "memory": {
        "command": "node",
        "args": ["YOUR_PATH/dist/index.js", "--user-id=YOUR_NAME"]
      }
    }
  }
}
```

---

### Gemini CLI
File: `~/.gemini/settings.json`

```json
{
  "mcpServers": {
    "memory": {
      "command": "node",
      "args": ["YOUR_PATH/dist/index.js", "--user-id=YOUR_NAME"]
    }
  }
}
```

---

### Any MCP Client (Generic)
The server uses **stdio transport**:
```bash
node YOUR_PATH/dist/index.js --user-id=YOUR_NAME
```

---

## ğŸ—ï¸ Firebase Setup (First Time Only)

1. Go to [console.firebase.google.com](https://console.firebase.google.com/) â†’ **Create a project**
2. Enable **Build â†’ Firestore Database** â†’ Create in **production mode**
3. **Project Settings** (âš™ï¸) â†’ **Service Accounts** â†’ **Generate new private key**
4. Save the file as **`serviceAccountKey.json`** in the project root

> âš ï¸ This file is gitignored. Never commit it.

### Optional: Semantic Search
Add **any one** API key to enable AI-powered similarity search:

```env
# Pick ONE â€” whichever you already have:
GEMINI_API_KEY=your_key_here          # Free (recommended)
OPENAI_API_KEY=your_key_here          # text-embedding-3-small
COHERE_API_KEY=your_key_here          # embed-english-v3.0

# Optional overrides:
EMBEDDING_PROVIDER=openai             # Force a specific provider
OPENAI_BASE_URL=https://your-api.com  # For Azure, Ollama, LM Studio, etc.
OPENAI_MODEL=text-embedding-3-large   # Custom model name
```

> **Auto-detection:** If no `EMBEDDING_PROVIDER` is set, the server picks the first key it finds (Gemini â†’ OpenAI â†’ Cohere). No key = smart fuzzy search (still works great).

---

## ğŸ§° All 15 Tools

| Tool | What It Does |
|---|---|
| `add_memory` | Save a new memory with optional tags |
| `get_memory` | Fetch a single memory by ID |
| `get_all_memories` | List memories (paginated, pinned first) |
| `search_memories` | Smart fuzzy search by text and/or tags |
| `semantic_search` | AI-powered similarity search (Gemini embeddings) |
| `update_memory` | Edit an existing memory |
| `delete_memory` | Delete a memory |
| `pin_memory` | Pin/unpin important memories |
| `add_memories` | Bulk add multiple memories at once |
| `delete_memories` | Bulk delete by IDs |
| `link_memories` | Create relationships between memories |
| `unlink_memories` | Remove relationships |
| `export_memories` | Export all memories as JSON |
| `import_memories` | Import memories (merge or replace) |
| `cleanup_expired` | Remove memories past their TTL |

### Example Prompts
```
"Remember that this project uses Next.js 15 with App Router"
â†’ add_memory(fact: "Project uses Next.js 15 with App Router", tags: ["tech-stack"])

"What do you know about my project setup?"
â†’ search_memories(query: "project setup")

"Link the auth memory to the API memory"
â†’ link_memories(sourceId: "abc", targetId: "xyz")
```

---

## ğŸ“Š Web Dashboard

| Page | Features |
|---|---|
| ğŸ“Š Dashboard | Stats, timeline, tag cloud, activity feed |
| ğŸ§  Memory Explorer | Search, filter, inline edit, pin/delete |
| ğŸ”— Knowledge Graph | Interactive D3.js force-directed visualization |
| ğŸ“¤ Import/Export | Download memories as JSON |
| ğŸ” Semantic Search | AI search with relevance scoring |
| âš™ï¸ Settings | Server info, connection guide |

---

## âœ¨ Key Features

| Feature | Description |
|---|---|
| ğŸ”„ **Multi-IDE Sync** | Same memory across Claude, Cursor, Windsurf, VS Code, Gemini CLI |
| ğŸ§  **Semantic Search** | Find memories by meaning, not just keywords (Gemini AI) |
| ğŸ“Œ **Pinned Memories** | Prioritize important facts |
| ğŸ”— **Memory Links** | Connect related memories into a knowledge graph |
| â° **Auto-Expiry (TTL)** | Memories can auto-delete after a set time |
| ğŸ“¦ **Bulk Operations** | Add/delete many memories at once |
| ğŸ“¤ **Import/Export** | Full backup and restore |
| ğŸ” **User Isolation** | Each `--user-id` gets its own private namespace |
| â˜ï¸ **Cloud Sync** | Real-time sync across all devices |
| ğŸ”„ **Auto-Retry** | Exponential backoff on transient errors |

---

## ğŸ“ Project Structure

```
mcp-memory-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts        # Entry point
â”‚   â”œâ”€â”€ config.ts       # CLI args + env vars
â”‚   â”œâ”€â”€ server.ts       # MCP tool registration (15 tools)
â”‚   â”œâ”€â”€ store.ts        # FirestoreMemoryStore (CRUD + search)
â”‚   â”œâ”€â”€ embeddings.ts   # Gemini AI embeddings
â”‚   â”œâ”€â”€ logger.ts       # Structured logger
â”‚   â””â”€â”€ types.ts        # TypeScript interfaces
â”œâ”€â”€ dashboard/          # Next.js web dashboard (6 pages)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ store.test.ts   # 19 unit tests
â”‚   â””â”€â”€ smoke.mjs       # Live Firestore smoke test
â”œâ”€â”€ setup.mjs           # One-command setup script
â”œâ”€â”€ serviceAccountKey.json  # (gitignored) Firebase credentials
â””â”€â”€ package.json
```

---

## ğŸ§ª Testing

```bash
npm test              # Unit tests (19 tests, all mocked)
node tests/smoke.mjs  # Smoke test against live Firestore
```

---

## âš™ï¸ Environment Variables

| Variable | Default | Description |
|---|---|---|
| `USER_ID` | â€” | Alternative to `--user-id` CLI flag |
| `GEMINI_API_KEY` | â€” | Gemini embeddings (free, default) |
| `OPENAI_API_KEY` | â€” | OpenAI embeddings |
| `OPENAI_BASE_URL` | `api.openai.com` | Custom endpoint (Azure, Ollama, LM Studio) |
| `OPENAI_MODEL` | `text-embedding-3-small` | Custom embedding model |
| `COHERE_API_KEY` | â€” | Cohere embeddings |
| `EMBEDDING_PROVIDER` | auto-detect | Force: `gemini`, `openai`, `cohere` |
| `LOG_LEVEL` | `info` | `debug`, `info`, `warn`, or `error` |

---

## ğŸ› ï¸ Troubleshooting

| Problem | Solution |
|---|---|
| `Missing serviceAccountKey.json` | Download from Firebase Console â†’ Project Settings â†’ Service Accounts |
| `Missing user authentication` | Add `--user-id=your-name` to the command |
| `PERMISSION_DENIED` | Enable Cloud Firestore API in Google Cloud Console |
| Server disconnected in IDE | Run `npm run build`, restart your IDE |
| Memories not syncing | Ensure all clients use the **same** `--user-id` |

---

## ğŸ“„ License

MIT
